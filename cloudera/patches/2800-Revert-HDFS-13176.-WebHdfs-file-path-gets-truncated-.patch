From e6ef156ad8ceca11a6dd2184c8fc2804fe9818fe Mon Sep 17 00:00:00 2001
From: Zsolt Venczel <zvenczel@cloudera.com>
Date: Wed, 2 May 2018 11:05:22 -0800
Subject: [PATCH 2800/2863] Revert "HDFS-13176. WebHdfs file path gets
 truncated when having semicolon inside.
 Contributed by Zsolt Venczel."

This reverts commit 3d4ba9bc82ee617307418ab250564120e16fb59d.

Change-Id: I0fbb2537f14ad5deb64eca60df3cee5c907fc795
---
 .../datanode/web/webhdfs/WebHdfsHandler.java       |    3 +-
 .../web/resources/NamenodeWebHdfsMethods.java      |    7 +--
 .../apache/hadoop/hdfs/web/WebHdfsFileSystem.java  |   27 +---------
 .../org/apache/hadoop/hdfs/web/TestWebHdfsUrl.java |   56 --------------------
 4 files changed, 4 insertions(+), 89 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java
index a2fe594..538af1d 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.java
@@ -59,7 +59,6 @@
 import java.net.InetSocketAddress;
 import java.net.URI;
 import java.net.URISyntaxException;
-import java.net.URLDecoder;
 import java.security.PrivilegedExceptionAction;
 import java.util.EnumSet;
 
@@ -119,7 +118,7 @@ public void channelRead0(final ChannelHandlerContext ctx,
     params = new ParameterParser(queryString, conf);
     DataNodeUGIProvider ugiProvider = new DataNodeUGIProvider(params);
     ugi = ugiProvider.ugi();
-    path = URLDecoder.decode(params.path(), "UTF-8");
+    path = params.path();
 
     injectToken();
     ugi.doAs(new PrivilegedExceptionAction<Void>() {
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java
index be4c4b2..bb6bdad 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java
@@ -25,7 +25,6 @@
 import java.net.InetAddress;
 import java.net.URI;
 import java.net.URISyntaxException;
-import java.net.URLDecoder;
 import java.security.PrivilegedExceptionAction;
 import java.util.EnumSet;
 import java.util.HashSet;
@@ -800,10 +799,8 @@ public Response get(
       @Override
       public Response run() throws IOException, URISyntaxException {
         try {
-          String absolutePath = path.getAbsolutePath() == null ? null :
-          URLDecoder.decode(path.getAbsolutePath(), "UTF-8");
-          return get(ugi, delegation, username, doAsUser, absolutePath,
-              op, offset, length, renewer, bufferSize,
+          return get(ugi, delegation, username, doAsUser,
+              path.getAbsolutePath(), op, offset, length, renewer, bufferSize,
               xattrNames, xattrEncoding, excludeDatanodes, fsAction, tokenKind,
               tokenService, startAfter);
         } finally {
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
index 8aa0d85..bbee493 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
@@ -31,8 +31,6 @@
 import java.net.MalformedURLException;
 import java.net.URI;
 import java.net.URL;
-import java.net.URLDecoder;
-import java.net.URLEncoder;
 import java.security.PrivilegedExceptionAction;
 import java.util.ArrayList;
 import java.util.EnumSet;
@@ -507,31 +505,8 @@ private URL getNamenodeURL(String path, String query) throws IOException {
   URL toUrl(final HttpOpParam.Op op, final Path fspath,
       final Param<?,?>... parameters) throws IOException {
     //initialize URI path and query
-    Path encodedFSPath = fspath;
-    if (fspath != null) {
-      URI fspathUri = fspath.toUri();
-      String fspathUriDecoded = fspathUri.getPath();
-      try {
-        fspathUriDecoded = URLDecoder.decode(fspathUri.getPath(), "UTF-8");
-      } catch (IllegalArgumentException ex) {
-        LOG.trace("Cannot decode URL encoded file", ex);
-      }
-      String[] fspathItems = fspathUriDecoded.split("/");
-
-      if (fspathItems.length > 0) {
-        StringBuilder fsPathEncodedItems = new StringBuilder();
-        for (String fsPathItem : fspathItems) {
-          fsPathEncodedItems.append("/");
-          fsPathEncodedItems.append(URLEncoder.encode(fsPathItem, "UTF-8"));
-        }
-        encodedFSPath = new Path(fspathUri.getScheme(),
-        fspathUri.getAuthority(), fsPathEncodedItems.substring(1));
-      }
-    }
-
     final String path = PATH_PREFIX
-        + (encodedFSPath == null ? "/" :
-        makeQualified(encodedFSPath).toUri().getRawPath());
+        + (fspath == null? "/": makeQualified(fspath).toUri().getRawPath());
     final String query = op.toQueryString()
         + Param.toSortedString("&", getAuthParameters(op))
         + Param.toSortedString("&", parameters);
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsUrl.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsUrl.java
index 2d5be03..75eb0f8 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsUrl.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsUrl.java
@@ -20,7 +20,6 @@
 
 import static org.apache.hadoop.security.UserGroupInformation.AuthenticationMethod.KERBEROS;
 import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
 import static org.mockito.Mockito.mock;
 
 import java.io.IOException;
@@ -30,14 +29,9 @@
 import java.util.Arrays;
 
 import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.LocatedFileStatus;
 import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.RemoteIterator;
 import org.apache.hadoop.fs.permission.FsAction;
-import org.apache.hadoop.hdfs.DFSTestUtil;
-import org.apache.hadoop.hdfs.MiniDFSCluster;
 import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;
 import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager;
 import org.apache.hadoop.hdfs.server.namenode.FSNamesystem;
@@ -364,54 +358,4 @@ private WebHdfsFileSystem getWebHdfsFileSystem(UserGroupInformation ugi,
     }
     return (WebHdfsFileSystem) FileSystem.get(uri, conf);
   }
-
-  private static final String SPECIAL_CHARACTER_FILENAME =
-          "specialFile ?\"\\()[]_-=&+;,{}#%'`~!@$^*|<>.";
-
-  @Test
-  public void testWebHdfsSpecialCharacterFile() throws Exception {
-    UserGroupInformation ugi =
-            UserGroupInformation.createRemoteUser("test-user");
-    ugi.setAuthenticationMethod(KERBEROS);
-    UserGroupInformation.setLoginUser(ugi);
-
-    final Configuration conf = WebHdfsTestUtil.createConf();
-    final Path dir = new Path("/testWebHdfsSpecialCharacterFile");
-
-    final short numDatanodes = 1;
-    final MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)
-            .numDataNodes(numDatanodes)
-            .build();
-    try {
-      cluster.waitActive();
-      final FileSystem fs = WebHdfsTestUtil
-              .getWebHdfsFileSystem(conf, WebHdfsFileSystem.SCHEME);
-
-      //create a file
-      final long length = 1L << 10;
-      final Path file1 = new Path(dir, SPECIAL_CHARACTER_FILENAME);
-
-      DFSTestUtil.createFile(fs, file1, length, numDatanodes, 20120406L);
-
-      //get file status and check that it was written properly.
-      final FileStatus s1 = fs.getFileStatus(file1);
-      assertEquals("Write failed for file " + file1, length, s1.getLen());
-
-      boolean found = false;
-      RemoteIterator<LocatedFileStatus> statusRemoteIterator =
-              fs.listFiles(dir, false);
-      while (statusRemoteIterator.hasNext()) {
-        LocatedFileStatus locatedFileStatus = statusRemoteIterator.next();
-        if (locatedFileStatus.isFile() &&
-                SPECIAL_CHARACTER_FILENAME
-                        .equals(locatedFileStatus.getPath().getName())) {
-          found = true;
-        }
-      }
-      assertFalse("Could not find file with special character", !found);
-    } finally {
-      cluster.shutdown();
-    }
-  }
-
 }
-- 
1.7.9.5

